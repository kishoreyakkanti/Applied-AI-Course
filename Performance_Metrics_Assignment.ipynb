{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Performance Metrics for Data 5_a.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba\n",
       "0  1.0  0.637387\n",
       "1  1.0  0.635165\n",
       "2  1.0  0.766586\n",
       "3  1.0  0.724564\n",
       "4  1.0  0.889199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"5_a.csv\") #loading Dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    10000\n",
       "0.0      100\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.637387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.766586</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.724564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba  y_predict\n",
       "0  1.0  0.637387          1\n",
       "1  1.0  0.635165          1\n",
       "2  1.0  0.766586          1\n",
       "3  1.0  0.724564          1\n",
       "4  1.0  0.889199          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"y_predict\"]=(data[\"proba\"]>=0.5)*1 #predicting values for Label \"y\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values=np.array(data[\"y\"]) #actual values of label \"y\"\n",
    "predicted_values=np.array(data[\"y_predict\"]) #predicted values of label \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate confusion matrix using actual and predicted values of \"y\"\n",
    "\n",
    "def cal_confusion_matrix(actual_values,predicted_values):\n",
    "    confusion_matrix=np.zeros((2,2),dtype=\"int\")\n",
    "    n=len(actual_values)\n",
    "    for i in range(n):\n",
    "        if actual_values[i]==0 and predicted_values[i]==0: #finding count of true negative\n",
    "            confusion_matrix[0,0]+=1\n",
    "        elif actual_values[i]==1 and predicted_values[i]==0: #count of false negative\n",
    "            confusion_matrix[0,1]+=1\n",
    "        elif actual_values[i]==0 and predicted_values[i]==1: #count of false postive\n",
    "            confusion_matrix[1,0]+=1\n",
    "        else:                         #count of true postive\n",
    "            confusion_matrix[1,1]+=1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is\n",
      "[[    0     0]\n",
      " [  100 10000]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "confusion_matrix=cal_confusion_matrix(actual_values,predicted_values)\n",
    "print(\"confusion matrix is\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is 0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "TN=confusion_matrix[0,0] # values of TN,FN,FP,TP\n",
    "FN=confusion_matrix[0,1] # from confusion matrix\n",
    "FP=confusion_matrix[1,0]\n",
    "TP=confusion_matrix[1,1]\n",
    "\n",
    "P=TP+FN #total count of postives\n",
    "N=FP+TN #total count of negatives\n",
    "\n",
    "\n",
    "precision=TP/(TP+FP) #precision formula\n",
    "#print(precision)\n",
    "\n",
    "recall=TP/(TP+FN) #recall formula\n",
    "#print(recall)\n",
    "\n",
    "F1_Score=2*precision*recall/(precision+recall) #calculating F1_SCORE using precision and recall\n",
    "print(\"F1 Score is {}\".format(F1_Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score is 0.48829900000000004 \n"
     ]
    }
   ],
   "source": [
    "proba=np.array(data[\"proba\"].sort_values(ascending=False)) #sorting probability values in descending order\n",
    "#print(proba)\n",
    "\n",
    "length=len(proba)\n",
    "tpr_values=[]\n",
    "fpr_values=[]\n",
    "y_values=np.array(data[\"y\"])\n",
    "for i in range(length):      \n",
    "    predict_values=np.array((data[\"proba\"]>=proba[i])*1)        #predicted values of \"y\" using\n",
    "    conf_matrix=cal_confusion_matrix(y_values,predict_values)   # different thresolds\n",
    "    TN_V=conf_matrix[0,0]\n",
    "    FN_V=conf_matrix[0,1]\n",
    "    FP_V=conf_matrix[1,0]\n",
    "    TP_V=conf_matrix[1,1]\n",
    "    P=TP_V+FN_V\n",
    "    N=FP_V+TN_V\n",
    "    tpr=TP_V/P\n",
    "    fpr=FP_V/N\n",
    "    tpr_values.append(tpr)\n",
    "    fpr_values.append(fpr)\n",
    "tpr_array=np.array(tpr_values) #TPR values for different thresolds\n",
    "fpr_array=np.array(fpr_values) #FPR values for different thresolds\n",
    "\n",
    "AUC_Score=np.trapz(tpr_array, fpr_array) #calculating AUC Using TPR AND FPR Values\n",
    "print(\"AUC Score is {} \".format(AUC_Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is 0.9900990099009901\n"
     ]
    }
   ],
   "source": [
    "accuracy_score=(TP+TN)/(TP+FP+TN+FN) #calculating accuracy score\n",
    "print(\"Accuracy Score is {}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Performance Metrics for Data 5_b.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba\n",
       "0  0.0  0.281035\n",
       "1  0.0  0.465152\n",
       "2  0.0  0.352793\n",
       "3  0.0  0.157818\n",
       "4  0.0  0.276648"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"5_b.csv\") #loading Dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    10000\n",
       "1.0      100\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>proba</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y     proba  y_predict\n",
       "0  0.0  0.281035          0\n",
       "1  0.0  0.465152          0\n",
       "2  0.0  0.352793          0\n",
       "3  0.0  0.157818          0\n",
       "4  0.0  0.276648          0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"y_predict\"]=(data[\"proba\"]>=0.5)*1 #predicting values for Label \"y\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values=np.array(data[\"y\"]) #actual values of label \"y\"\n",
    "#print(actual_values)\n",
    "predicted_values=np.array(data[\"y_predict\"]) #predicted values of label \"y\"\n",
    "#print(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate confusion matrix using actual and predicted values of \"y\"\n",
    "\n",
    "def cal_confusion_matrix(actual_values,predicted_values):\n",
    "    confusion_matrix=np.zeros((2,2),dtype=\"int\")\n",
    "    n=len(actual_values)\n",
    "    for i in range(n):\n",
    "        if actual_values[i]==0 and predicted_values[i]==0:   #count of true negative\n",
    "            confusion_matrix[0,0]+=1\n",
    "        elif actual_values[i]==1 and predicted_values[i]==0:   #count of false negative\n",
    "            confusion_matrix[0,1]+=1\n",
    "        elif actual_values[i]==0 and predicted_values[i]==1:   #countpf false postive\n",
    "            confusion_matrix[1,0]+=1\n",
    "        else:                             #count of true postive\n",
    "            confusion_matrix[1,1]+=1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is\n",
      "[[9761   45]\n",
      " [ 239   55]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "confusion_matrix=cal_confusion_matrix(actual_values,predicted_values)\n",
    "print(\"confusion matrix is\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is 0.2791878172588833\n"
     ]
    }
   ],
   "source": [
    "TN=confusion_matrix[0,0] # values of TN,FN,FP,TP\n",
    "FN=confusion_matrix[0,1] # from confusion matrix\n",
    "FP=confusion_matrix[1,0]\n",
    "TP=confusion_matrix[1,1]\n",
    "\n",
    "P=TP+FN #total postives\n",
    "N=FP+TN #total negatives\n",
    "\n",
    "\n",
    "precision=TP/(TP+FP) #precision formula\n",
    "#print(precision)\n",
    "\n",
    "recall=TP/(TP+FN) #recall formula\n",
    "#print(recall)\n",
    "\n",
    "F1_Score=2*precision*recall/(precision+recall) #calculating F1_SCORE using precision and recall\n",
    "print(\"F1 Score is {}\".format(F1_Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score is 0.9377570000000001 \n"
     ]
    }
   ],
   "source": [
    "proba=np.array(data[\"proba\"].sort_values(ascending=False))  #sorting probability values in descending order\n",
    "#print(proba)\n",
    "\n",
    "length=len(proba)\n",
    "tpr_values=[]\n",
    "fpr_values=[]\n",
    "y_values=np.array(data[\"y\"])\n",
    "for i in range(length): \n",
    "    predict_values=np.array((data[\"proba\"]>=proba[i])*1)         #predicted values of \"y\" using\n",
    "    conf_matrix=cal_confusion_matrix(y_values,predict_values)    # different thresolds\n",
    "    TN_V=conf_matrix[0,0]\n",
    "    FN_V=conf_matrix[0,1]\n",
    "    FP_V=conf_matrix[1,0]\n",
    "    TP_V=conf_matrix[1,1]\n",
    "    P=TP_V+FN_V\n",
    "    N=FP_V+TN_V\n",
    "    tpr=TP_V/P\n",
    "    fpr=FP_V/N\n",
    "    tpr_values.append(tpr)\n",
    "    fpr_values.append(fpr)\n",
    "tpr_array=np.array(tpr_values)   #TPR values for different thresolds\n",
    "fpr_array=np.array(fpr_values)    #FPR values for different thresolds\n",
    "\n",
    "AUC_Score=np.trapz(tpr_array, fpr_array)  #calculating AUC Using TPR AND FPR Values\n",
    "print(\"AUC Score is {} \".format(AUC_Score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score is 0.9718811881188119\n"
     ]
    }
   ],
   "source": [
    "accuracy_score=(TP+TN)/(TP+FP+TN+FN) #calculating accuracy score\n",
    "print(\"Accuracy Score is {}\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Best Thresold of Metric A for Data 5_c.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.505037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.418652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.412057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.375579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y      prob\n",
       "0  0  0.458521\n",
       "1  0  0.505037\n",
       "2  0  0.418652\n",
       "3  0  0.412057\n",
       "4  0  0.375579"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"5_c.csv\")   #loading dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1805\n",
       "1    1047\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"y\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate confusion matrix using actual and predicted values of \"y\"\n",
    "\n",
    "def cal_confusion_matrix(actual_values,predicted_values):\n",
    "    confusion_matrix=np.zeros((2,2),dtype=\"int\")\n",
    "    n=len(actual_values)\n",
    "    for i in range(n):\n",
    "        if actual_values[i]==0 and predicted_values[i]==0:    #count of true negative\n",
    "            confusion_matrix[0,0]+=1\n",
    "        elif actual_values[i]==1 and predicted_values[i]==0:   #fcount of alse negative\n",
    "            confusion_matrix[0,1]+=1\n",
    "        elif actual_values[i]==0 and predicted_values[i]==1:  # count of false postive\n",
    "            confusion_matrix[1,0]+=1\n",
    "        else:                              # count of true postive\n",
    "            confusion_matrix[1,1]+=1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba=np.array(data[\"prob\"].sort_values(ascending=False))  #sorting probability values in descending order\n",
    "#print(proba)\n",
    "\n",
    "length=len(proba)\n",
    "A_metric=[]\n",
    "y_values=np.array(data[\"y\"]) #actual values of label \"y\"\n",
    "for i in range(length):\n",
    "    predict_values=np.array((data[\"prob\"]>=proba[i])*1)         #predicted values of \"y\" using\n",
    "    conf_matrix=cal_confusion_matrix(y_values,predict_values)    # different thresolds\n",
    "    FN=conf_matrix[0,1]\n",
    "    FP=conf_matrix[1,0]\n",
    "    A=500*FN+100*FP        # calculating A metrices\n",
    "    A_metric.append(A)\n",
    "A_array=np.array(A_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold with lowest value of metric A is\n",
      "0.2300390278970873\n"
     ]
    }
   ],
   "source": [
    "A_min=A_array.min()\n",
    "A_min_index=A_array.argmin()  #getting index of minimum value of A\n",
    "#print(A_min)\n",
    "#print(A_min_index)\n",
    "\n",
    "print(\"Best threshold with lowest value of metric A is\")\n",
    "print(proba[A_min_index]) ##getting best thresold value from index A_min_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Performance Metrics(for regression) for Data 5_d.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y   pred\n",
       "0  101.0  100.0\n",
       "1  120.0  100.0\n",
       "2  131.0  113.0\n",
       "3  164.0  125.0\n",
       "4  154.0  152.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"5_d.csv\")   # loading dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error is 177.16569974554707\n"
     ]
    }
   ],
   "source": [
    "y=np.array(data[\"y\"])        # given actual values of \"y\"\n",
    "y_cap=np.array(data[\"pred\"])  #given predicted values of \"y\"\n",
    "\n",
    "Mean_Square_Error=np.mean(np.square(y-y_cap))  #calculating Mean Square Error\n",
    "print(\"Mean Square Error is {}\".format(Mean_Square_Error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error is 12.91202994009687\n"
     ]
    }
   ],
   "source": [
    "sum_absolute_errors=np.sum((np.absolute(y-y_cap)))  #sum of absolute errors\n",
    "sum_actual_values=np.sum(y)                          #sum of actual values of \"y\"\n",
    "\n",
    "MAPE=(sum_absolute_errors/sum_actual_values)*100     #mean absolute pecentage error formula\n",
    "print(\"Mean Absolute Percentage Error is {}\".format(MAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Error is\n",
      "0.9563582786990937\n"
     ]
    }
   ],
   "source": [
    "total_sum_of_squares=np.sum(np.square(y-np.mean(y)))   #total sum of squares SS_tot\n",
    "sum_of_squares_of_residuals=np.sum(np.square(y-y_cap))  #sum of squares of residuals SS_res\n",
    "\n",
    "R2_Error=1-(sum_of_squares_of_residuals/total_sum_of_squares)  #Rsquare_Error=1-(SS_res/SS_total)\n",
    "print(\"R^2 Error is\")\n",
    "print(R2_Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
